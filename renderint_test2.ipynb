{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039d1c9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bce47a5e",
   "metadata": {},
   "source": [
    "# Worked example (pen-and-paper): constrained ↔ penalized (Lagrangian) for ridge\n",
    "\n",
    "**Goal.** Work a concrete, tiny example by hand so you can see step-by-step how the constrained problem and the penalized (ridge) problem are the same for an appropriate choice of multiplier. We keep everything scalar so algebra is simple and you can follow with pencil and paper.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem statement (very small data)\n",
    "\n",
    "We fit a model $y \\approx x\\beta$ with one scalar parameter $\\beta$. Data:\n",
    "\n",
    "$$\n",
    "x = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix},\\qquad\n",
    "y = \\begin{bmatrix}1 \\\\ 2.2\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Define the least-squares objective (sum of squared errors):\n",
    "\n",
    "$$\n",
    "f(\\beta) = \\sum_{i=1}^2 (x_i\\beta - y_i)^2.\n",
    "$$\n",
    "\n",
    "We will compare:\n",
    "\n",
    "- **Unconstrained OLS**: $\\min_\\beta f(\\beta)$.\n",
    "- **Constrained**: $\\min_\\beta f(\\beta)$ subject to $\\beta^2 \\le c$ (choose $c$ later).\n",
    "- **Penalized (Ridge)**: $\\min_\\beta f(\\beta) + \\lambda \\beta^2$.\n",
    "\n",
    "You will see the same solution appear for a particular relation between $c$ and $\\lambda$.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1 — compute some sums (do these first)\n",
    "\n",
    "Work out the two sums you will use repeatedly (do with pencil):\n",
    "\n",
    "$$\n",
    "S_{xx} = \\sum_i x_i^2 = 1^2 + 2^2 = 1 + 4 = 5.\n",
    "$$\n",
    "$$\n",
    "S_{xy} = \\sum_i x_i y_i = 1\\cdot 1 + 2\\cdot 2.2 = 1 + 4.4 = 5.4.\n",
    "$$\n",
    "\n",
    "These are simple and important. Keep them visible.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2 — solve the unconstrained least squares (OLS)\n",
    "\n",
    "For scalar $\\beta$, the normal equation reduces to:\n",
    "\n",
    "$$\n",
    "S_{xx}\\,\\beta = S_{xy} \\quad\\Longrightarrow\\quad \\beta_{\\text{OLS}} = \\frac{S_{xy}}{S_{xx}}.\n",
    "$$\n",
    "\n",
    "Plug numbers:\n",
    "\n",
    "$$\n",
    "\\beta_{\\text{OLS}} = \\frac{5.4}{5} = 1.08.\n",
    "$$\n",
    "\n",
    "**Interpretation:** with no constraints, the best fit coefficient is $1.08$.\n",
    "\n",
    "Compute its squared norm (we will compare to $c$):\n",
    "\n",
    "$$\n",
    "\\beta_{\\text{OLS}}^2 = 1.08^2 = 1.1664.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3 — set a constraint and check if it is active\n",
    "\n",
    "Pick a constraint radius. For the example, take\n",
    "\n",
    "$$\n",
    "c = 1 \\quad(\\text{so the allowed }|\\beta|\\le 1).\n",
    "$$\n",
    "\n",
    "Compare $\\beta_{\\text{OLS}}^2 = 1.1664$ with $c=1$. Since $1.1664 > 1$, the unconstrained solution violates the constraint. Therefore the constraint is **active**: the constrained minimizer lies on the boundary $\\beta^2 = c$.\n",
    "\n",
    "So the constrained solution is **not** $\\beta_{\\text{OLS}}$ — it will be on the circle/point $\\beta = \\pm \\sqrt{c}$. (Because for scalar parameter and a convex symmetric problem we expect the positive sign here.)\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4 — form the Lagrangian for the constrained problem\n",
    "\n",
    "Write the constrained problem:\n",
    "\n",
    "$$\n",
    "\\min_\\beta f(\\beta) \\quad\\text{s.t.}\\quad \\beta^2 \\le c.\n",
    "$$\n",
    "\n",
    "Form the Lagrangian (use multiplier $\\mu\\ge0$):\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\beta,\\mu) = f(\\beta) + \\mu(\\beta^2 - c).\n",
    "$$\n",
    "\n",
    "(We write constraint as $\\beta^2 - c \\le 0$; the sign is conventional. The constant $-\\mu c$ does not affect minimization over $\\beta$, but we keep $\\mu$ to enforce the boundary.)\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5 — stationarity (first-order condition)\n",
    "\n",
    "Differentiate the Lagrangian w.r.t.\\ $\\beta$ and set derivative to zero.\n",
    "\n",
    "For our data,\n",
    "$$\n",
    "f(\\beta) = (1\\cdot\\beta -1)^2 + (2\\cdot\\beta - 2.2)^2.\n",
    "$$\n",
    "Differentiate on paper (or use the compact sums):\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\beta} f(\\beta) = 2S_{xx}\\,\\beta - 2S_{xy}.\n",
    "$$\n",
    "\n",
    "(You can check this: expand the two squared terms and differentiate term by term.)\n",
    "\n",
    "Including the $\\mu$ term, stationarity is:\n",
    "\n",
    "$$\n",
    "0 = \\frac{\\partial\\mathcal{L}}{\\partial\\beta}\n",
    "  = (2S_{xx}\\beta - 2S_{xy}) + 2\\mu\\beta.\n",
    "$$\n",
    "\n",
    "Rearrange:\n",
    "\n",
    "$$\n",
    "(2S_{xx} + 2\\mu)\\beta = 2S_{xy}.\n",
    "$$\n",
    "\n",
    "Divide by 2:\n",
    "\n",
    "$$\n",
    "(S_{xx} + \\mu)\\,\\beta = S_{xy}.\n",
    "$$\n",
    "\n",
    "So the **stationarity formula** for the constrained problem is\n",
    "\n",
    "$$\n",
    "\\boxed{\\beta(\\mu) = \\frac{S_{xy}}{S_{xx} + \\mu}.}\n",
    "$$\n",
    "\n",
    "This is the same algebraic form as ridge — note the appearance of $\\mu$ added to $S_{xx}$.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6 — use the boundary condition (complementary slackness)\n",
    "\n",
    "Because we already determined the constraint is active for $c=1$, complementary slackness says $\\mu>0$ and $\\beta^2 = c$.\n",
    "\n",
    "So set $\\beta = \\pm\\sqrt{c}$. We choose the positive root because the unconstrained solution was positive and the problem is symmetric: $\\beta = +1$.\n",
    "\n",
    "Plug into the stationarity formula to solve for $\\mu$:\n",
    "\n",
    "$$\n",
    "1 = \\frac{S_{xy}}{S_{xx} + \\mu}\n",
    "\\quad\\Longrightarrow\\quad S_{xx} + \\mu = S_{xy}.\n",
    "$$\n",
    "\n",
    "Thus\n",
    "\n",
    "$$\n",
    "\\mu = S_{xy} - S_{xx}.\n",
    "$$\n",
    "\n",
    "Use numbers: $S_{xy}=5.4$, $S_{xx}=5$:\n",
    "\n",
    "$$\n",
    "\\mu = 5.4 - 5 = 0.4.\n",
    "$$\n",
    "\n",
    "So the Lagrange multiplier that enforces the constraint $\\beta^2\\le1$ is $\\mu = 0.4$, and the constrained solution is $\\beta = 1$.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 7 — check the penalized (ridge) problem with $\\lambda=\\mu$\n",
    "\n",
    "Now consider the penalized objective with $\\lambda = 0.4$:\n",
    "\n",
    "$$\n",
    "\\min_\\beta f(\\beta) + \\lambda \\beta^2.\n",
    "$$\n",
    "\n",
    "The stationarity (derivative = 0) gives exactly the same linear equation as in Step 5:\n",
    "\n",
    "$$\n",
    "(S_{xx} + \\lambda)\\beta = S_{xy}.\n",
    "$$\n",
    "\n",
    "Plug $\\lambda=0.4$:\n",
    "\n",
    "$$\n",
    "(5 + 0.4)\\beta = 5.4 \\quad\\Longrightarrow\\quad 5.4\\,\\beta = 5.4 \\quad\\Longrightarrow\\quad \\beta = 1.\n",
    "$$\n",
    "\n",
    "So with $\\lambda=0.4$ the penalized (ridge) minimizer equals the constrained minimizer we found earlier. **This demonstrates the equivalence** in this concrete case.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 8 — verify KKT conditions quickly (conceptual check)\n",
    "\n",
    "For completeness, verify the four KKT conditions:\n",
    "\n",
    "1. **Primal feasibility:** $\\beta^2 \\le c$. We have $\\beta=1$, $1^2 = 1 \\le 1$ ✓.\n",
    "2. **Dual feasibility:** $\\mu \\ge 0$. We have $\\mu=0.4 \\ge 0$ ✓.\n",
    "3. **Stationarity:** satisfied by construction: $(S_{xx}+\\mu)\\beta=S_{xy}$ ✓.\n",
    "4. **Complementary slackness:** $\\mu(\\beta^2 - c)=0$. Since $\\beta^2 - c = 0$ and $\\mu>0$, product is 0 ✓.\n",
    "\n",
    "All **KKT conditions** hold, so this is a valid optimal solution.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 9 — try a different $c$ by hand (exercise)\n",
    "\n",
    "Do this with pencil and paper to see the monotonic mapping $\\mu \\leftrightarrow c$.\n",
    "\n",
    "1. If you pick $c = 2$ (a loose constraint), unconstrained $\\beta_{\\text{OLS}}^2 = 1.1664 < 2$. The constraint is **inactive**, so $\\mu=0$ and the constrained minimizer is $\\beta_{\\text{OLS}}=1.08$. The penalized form with $\\lambda=0$ matches (OLS).\n",
    "\n",
    "2. If you pick $c$ smaller, e.g. $c=0.25$ (so allowed $|\\beta|\\le 0.5$), you can solve for $\\mu$ from the equation\n",
    "   $$\n",
    "   \\beta = \\frac{S_{xy}}{S_{xx}+\\mu},\\qquad \\beta^2 = c .\n",
    "   $$\n",
    "   Combine: $\\sqrt{c} = S_{xy}/(S_{xx}+\\mu)$ → solve for $\\mu$:\n",
    "   $$\n",
    "   \\mu = \\frac{S_{xy}}{\\sqrt{c}} - S_{xx}.\n",
    "   $$\n",
    "   Plug numbers and verify $\\mu>0$. Then the penalized solution with $\\lambda=\\mu$ gives the same $\\beta$.\n",
    "\n",
    "This exercise shows the mapping $\\mu \\mapsto \\beta(\\mu)$ is decreasing: larger $\\mu$ produces smaller $|\\beta|$.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 10 — takeaways (simple and important)\n",
    "\n",
    "- The stationarity equation $(S_{xx}+\\mu)\\beta = S_{xy}$ is **exactly** the ridge normal equation when you set $\\lambda=\\mu$.\n",
    "- For scalar problems you can explicitly solve for $\\mu$ from the boundary condition $\\beta^2=c$. In matrix/vector problems the idea is the same but solving for the dual multiplier analytically is harder.\n",
    "- **In practice** we pick $\\lambda$ (the penalty) by validation rather than solving for a particular $c$. The mathematics shows that each $\\lambda$ corresponds to some constraint radius $c$ (and vice versa), under convexity.\n",
    "- The KKT conditions are the formal set of equations that guarantee optimality and formalize the equivalence.\n",
    "\n",
    "---\n",
    "\n",
    "## Checklist to reproduce this example by hand\n",
    "\n",
    "1. Compute $S_{xx}$ and $S_{xy}$.\n",
    "2. Compute $\\beta_{\\text{OLS}} = S_{xy}/S_{xx}$. Check $\\beta_{\\text{OLS}}^2$ vs $c$.\n",
    "3. If unconstrained solution violates constraint (active), form stationarity:\n",
    "   $(S_{xx} + \\mu)\\beta = S_{xy}$.\n",
    "4. Use boundary $\\beta^2 = c$ to solve for $\\mu$. (For scalar this is direct.)\n",
    "5. Plug $\\lambda=\\mu$ into the penalized equation $(S_{xx}+\\lambda)\\beta=S_{xy}$ and verify same $\\beta$.\n",
    "6. Check KKT conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f3347",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
